{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what is the defference between supervised/unsupervised learning?\n",
    "\n",
    "supervised learning:\n",
    "\n",
    "learning a function that takes input data and produces outputs where the learning single comes from a set of labelled data points (usually labelled by humans). example: regression, neural nets.\n",
    "\n",
    "unsupervised learning:\n",
    "\n",
    "learning a function that takes input data and produces outputs where the learning singal comes from inherent structure n the data itself; usually there are no labels in this type of learning.  example: k-means, reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression\n",
    "\n",
    "**description**\n",
    "\n",
    "regression is a technique that predicts come output vlaue for a set of inputs. it usually takes some input variables and outputs a continuous value.  i\n",
    "\n",
    "**math**\n",
    "\n",
    "the morst basic form of linera regression takes the form $y = b + w_1x_1 + w_2x_2 ...$ where the x variables are the inputs, w are the weights/coefficients for those inputs. and b is a constant term that cna shift the regression up or down along the y axis to get it to fit the data better.\n",
    "\n",
    "**example**\n",
    "\n",
    "predicting height from age, gender, and ethnicity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification\n",
    "\n",
    "**description**\n",
    "\n",
    "classification is a technique used for predicting what type of thing an input is. usually this involves having some number of classes (dog or cat for example) and picking one for some input or set of inputs.\n",
    "\n",
    "**math**\n",
    "\n",
    "the simplest form of classification is logistic regression. it is a process to separate two sets of datapoints into two different groups.\n",
    "\n",
    "**example**\n",
    "\n",
    "drawing a boundary line for men/women based on height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regularization\n",
    "\n",
    "**description**\n",
    "\n",
    "regularization is a technique used to manage 'high variance' models. you model can be too flexible and overfit the dataset. for example a model that runs through every single point will probably be bad at predicting new points. to smooth out your model you can use regulariation to make it fit less closely to the original dataset. models that have been smoothed/regularized tend to predict new data with a lower error than overfitted models.\n",
    "\n",
    "**math**\n",
    "\n",
    "the simplest form of regression is something like this:\n",
    "\n",
    "$y = b + w_1x_1 + w_2x_2 ...$\n",
    "\n",
    "$e = \\sum(y_i-y_L)^2 + n^2$\n",
    "\n",
    "where n is the number of coefficients you have, basically this increases the error $e$ if you use more coefficients.\n",
    "\n",
    "**example**\n",
    "\n",
    "\n",
    "other sources:\n",
    "\n",
    "https://stats.stackexchange.com/questions/4272/when-to-use-regularization-methods-for-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimensionality reduction\n",
    "\n",
    "**description**\n",
    "\n",
    "this is the process of reducing the number of inputs your model sees usually to make it easier to find a pattern. feature selection and extraction are both parts of dimensionalit reduction.\n",
    "\n",
    "**math:**\n",
    "\n",
    "PCA\n",
    "\n",
    "**example:**\n",
    "\n",
    "other sources:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Dimensionality_reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster analysis\n",
    "\n",
    "**description**\n",
    "\n",
    "this is a technique that is similar to classification algorithms. it groups similar data points together and can be used to select features, or to understand more relationships about your dataset that may not appear on the surface.\n",
    "\n",
    "**math:**\n",
    "\n",
    "\n",
    "\n",
    "**example:**\n",
    "\n",
    "k means\n",
    "\n",
    "other sources:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Cluster_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimization\n",
    "\n",
    "**description**\n",
    "\n",
    "optimization is the practice of finding a solution which maximizes or minimizes some metric. for example you might choose to minimize a loss function of your model or algorithm.\n",
    "\n",
    "**math:**\n",
    "\n",
    "**example:**\n",
    "\n",
    "regression, minimizing binary cross entropy.\n",
    "\n",
    "other sources:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Mathematical_optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recommender systems\n",
    "\n",
    "**description**\n",
    "\n",
    "this is class of information filtering system that tries to predict what type of item a user might what or what kind of ranking/rating a user might give to a particular item.\n",
    "\n",
    "**math:**\n",
    "\n",
    "**example:**\n",
    "\n",
    "other sources:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Recommender_system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering\n",
    "\n",
    "**description**\n",
    "\n",
    "is a process of turning your raw data into a structure that a machine learning algorithm can learn or or process (or do those things more easily). some algorithms, like a neural net, are themselves a form of feature engineering (the neurons being latent features). feature engineering can include the construction of new features or the transformation of existing features (whitening/normalization).\n",
    "\n",
    "**math:**\n",
    "\n",
    "**example:**\n",
    "\n",
    "other sources:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Feature_engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection\n",
    "\n",
    "**description**\n",
    "\n",
    "is the process of choosing some subset of features to use in your model and discarding others. some features may be redundant. having too many features can actually make your model worse or increase training time so they need to be removed.\n",
    "\n",
    "**math:**\n",
    "\n",
    "**example:**\n",
    "\n",
    "other sources:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# natural language processing\n",
    "\n",
    "**description**\n",
    "\n",
    "natural languge processing (nlp) is a set of tool and techniques to help computers parse, break down, and interpret natural human language. this topic encompasses models (generative and discriminative), tokenziation libraries, as well as vecotr math that can represent language mathematically in a latent space.\n",
    "\n",
    "**math:**\n",
    "\n",
    "**example:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model selection/evaluation\n",
    "\n",
    "**description**\n",
    "\n",
    "a process of choosing the best model among several candidates. often such experiments revolve around determining whether more complex models perform better and exploring this tradeoff for the problem you are trying to solve. often to choose a model models are tested and evaluated on a set of data for which the labels are knonw (a test set). the evaluatio metric is an art unto itself; usually the simpler (single number) the better.\n",
    "\n",
    "**math:**\n",
    "\n",
    "**example:**\n",
    "\n",
    "other sources:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Model_selection\n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# curse of dimensionality\n",
    "\n",
    "**description**\n",
    "\n",
    "dimensionality adds information in terms of dimesions but incraeses the 'space' inside the dataset exponentially. your data ends up being sparse; sparse data is very difficult for many ml models to find patterns in. so the curse is that as your data gets new dimensions along which more information can exist, many rows will lack that dimension and so increase the sparsity of yoru dataset.\n",
    "\n",
    "**math:**\n",
    "\n",
    "**example:**\n",
    "\n",
    "other sources:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Curse_of_dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
